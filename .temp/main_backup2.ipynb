{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7269907016b4ac8",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# GSP Final Project\n",
    "In this notebook, we will demonstrate estimation of graph signals using a GSP-based technique vs.  a deep-learning-based technique. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51bc23eb3352395a",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T15:37:32.885168900Z",
     "start_time": "2024-04-24T15:37:30.706210Z"
    }
   },
   "outputs": [],
   "source": [
    "import util\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import scipy.sparse as ssparse\n",
    "import scipy.io as sio\n",
    "import torch_geometric as tg\n",
    "import matplotlib.pyplot as plt\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf0bb1d0827071d9",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-22T14:41:56.954085500Z",
     "start_time": "2024-04-22T14:41:56.744596700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Apr 22 17:41:56 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 552.22                 Driver Version: 552.22         CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                     TCC/WDDM  | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4060 ...  WDDM  |   00000000:01:00.0  On |                  N/A |\n",
      "| N/A   38C    P8              3W /   55W |     715MiB /   8188MiB |      3%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A     10320    C+G   C:\\Windows\\explorer.exe                     N/A      |\n",
      "|    0   N/A  N/A     11972    C+G   ...nt.CBS_cw5n1h2txyewy\\SearchHost.exe      N/A      |\n",
      "|    0   N/A  N/A     12092    C+G   ...2txyewy\\StartMenuExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A     12600    C+G   ...utube-music\\3.2.2\\YouTube Music.exe      N/A      |\n",
      "|    0   N/A  N/A     16784    C+G   ...ys\\WinUI3Apps\\PowerToys.Peek.UI.exe      N/A      |\n",
      "|    0   N/A  N/A     16812    C+G   ...crosoft\\Edge\\Application\\msedge.exe      N/A      |\n",
      "|    0   N/A  N/A     17564    C+G   ...werToys\\PowerToys.PowerLauncher.exe      N/A      |\n",
      "|    0   N/A  N/A     17708    C+G   ...ekyb3d8bbwe\\PhoneExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A     18124    C+G   ...GeForce Experience\\NVIDIA Share.exe      N/A      |\n",
      "|    0   N/A  N/A     18172    C+G   ...t.LockApp_cw5n1h2txyewy\\LockApp.exe      N/A      |\n",
      "|    0   N/A  N/A     18604    C+G   ...on\\123.0.2420.97\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A     18768    C+G   ...CBS_cw5n1h2txyewy\\TextInputHost.exe      N/A      |\n",
      "|    0   N/A  N/A     20524    C+G   ...les\\Microsoft OneDrive\\OneDrive.exe      N/A      |\n",
      "|    0   N/A  N/A     20808    C+G   ...Programs\\Microsoft VS Code\\Code.exe      N/A      |\n",
      "|    0   N/A  N/A     21472    C+G   ...ASUSACCI\\ArmouryCrateKeyControl.exe      N/A      |\n",
      "|    0   N/A  N/A     21860    C+G   ...Google\\NearbyShare\\nearby_share.exe      N/A      |\n",
      "|    0   N/A  N/A     21872    C+G   ...8.0_x64__cv1g1gvanyjgm\\WhatsApp.exe      N/A      |\n",
      "|    0   N/A  N/A     29680    C+G   ...5n1h2txyewy\\ShellExperienceHost.exe      N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# Enable CUDA\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Not connected to a GPU')\n",
    "else:\n",
    "  print(gpu_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9c2d7b0168bd9c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Task\n",
    "\n",
    "$$\\mathbf{x} \\longrightarrow  \\boxed{\\text{Physical Model}} \\longrightarrow \\mathbf{y}  \\longrightarrow \\boxed{\\text{Estimator}}  \\longrightarrow \\hat{\\mathbf{x}}$$ \n",
    "\n",
    "### Physical Model\n",
    "$$ \\mathbf{y} = \\mathbf{g}(\\mathbf{x};\\mathbf{L}) + \\mathbf{w} $$\n",
    "\n",
    "- $\\mathbf{x} \\sim p(\\mathbf{x})$.\n",
    "- $\\mathbf{g}$ - a non-linear measurement function.\n",
    "- $\\mathbf{L}$ - the Laplacian matrix of the graph.\n",
    " \n",
    "### Estimator\n",
    "- $\\mathbf{y}$ - input of the estimator\n",
    "- $\\mathbf{x}$ - ground-truth corresponding label\n",
    "- The estimator is given a dataset pairs of $\\{\\mathbf{x_t}, \\mathbf{y_t} \\}_t$ for training.\n",
    "\n",
    "**Goal**: The estimator should recover $\\mathbf{x}$ out of $\\mathbf{y}$ with minimum MSE.\n",
    "#### GSP-based\n",
    "\n",
    "Use a GSP-based technique for estimation.\n",
    "\n",
    "#### GNN-based\n",
    "\n",
    "Use a GNN deep-learning architecture for estimation.\n",
    "\n",
    "**NOTE:**  $\\mathbf{y}$ is the input to the DP model and $\\mathbf{x}$ is the output (i.e., the label) not vise versa!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5f862e6b2a95fa",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Part 1: Physical Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "860a8f216a91cbae",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T15:37:36.852339100Z",
     "start_time": "2024-04-24T15:37:36.846692700Z"
    }
   },
   "outputs": [],
   "source": [
    "def laplacian_evd(Y):\n",
    "    L = - np.imag(Y)\n",
    "    Lambda, V = np.linalg.eig(L)\n",
    "    Lambda = np.real(Lambda)\n",
    "    sorted_indices = np.argsort(Lambda)\n",
    "    Lambda = Lambda[sorted_indices]\n",
    "    Lambda = np.diag(Lambda)\n",
    "    V = V[:, sorted_indices]\n",
    "    return L, Lambda, V\n",
    "    \n",
    "def g_xL(Y, x):\n",
    "    v = np.exp(1j * x)\n",
    "    g_x = np.real(v * np.conj(Y @ v))\n",
    "    return g_x\n",
    "    \n",
    "def generate_data(nt, Y, Lambda, V, beta=3, c_ww=0.05):\n",
    "    N = Y.shape[0]\n",
    "    xt = (V[:, 1:] @ np.random.multivariate_normal(np.zeros(N - 1), beta * np.diag(1 / np.diag(Lambda)[1:]), nt).T).T\n",
    "    if nt == 1:\n",
    "        xt = xt[0, :]\n",
    "    \n",
    "    yt = np.zeros(xt.shape)\n",
    "    for t in range(0, nt):\n",
    "        yt[t] = g_xL(Y, xt[t])\n",
    "    yt += np.sqrt(c_ww) * np.random.randn(yt.shape[0], yt.shape[1])\n",
    "    \n",
    "    return xt, yt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1667db35646052",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Part 2: GSP-LMMSE Estimator\n",
    "\n",
    "The GSP-LMMSE estimator is defined as an estimator which minimize the MSE among all estimators in the form of a graph filter:\n",
    "$$\n",
    "\\{\\bf{h}, \\bf{b} \\} = \\text{argmin}~ \\mathbb{E} [(\\bf{x} - \\hat{\\bf{x}}(\\bf{y}))^2]\n",
    "$$\n",
    "\n",
    "where $\\hat{\\bf{x}}(\\bf{y}) =  \\bf{V} \\text{diag} (\\bf{h}) \\bf{V}^T \\bf{y}+ \\bf{b}$.\n",
    "\n",
    "A closed form expression would be:\n",
    "$$ \\hat{\\bf{x}}(\\bf{y}) =  \\bf{V} \\text{diag} (\\bf{d}_{\\bf{xy}}\\oslash \\bf{d}_{\\bf{yy}}) \\bf{V}^T \\bf{y} + \\bar{\\bf{x}}$$\n",
    "\n",
    "where $\\bf{d}_{\\bf{xy}} := \\text{diag}(\\text{cov}(\\bf{V}^T \\bf{x}, \\bf{V}^T \\bf{y}))$, $\\bf{d}_{\\bf{yy}} := \\text{diag}(\\text{var}(\\bf{V}^T \\bf{y}))$ and $\\bar{\\bf{x}} :=\\mathbb{E}\\bf{x}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b344e0714d5c5312",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T15:37:39.719062900Z",
     "start_time": "2024-04-24T15:37:39.714605100Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_gsp_lmmse_estimator(xt, yt, V):\n",
    "    xt = xt.T     # column vectors representation\n",
    "    yt = yt.T     # column vectors representation\n",
    "\n",
    "    xt_mean = np.mean(xt, axis=1)[:, np.newaxis]\n",
    "    yt_mean = np.mean(yt, axis=1)[:, np.newaxis]\n",
    "\n",
    "    d_xy = np.mean( ( V.T @ (xt - xt_mean) ) * ( V.T @ (yt - yt_mean) ) , axis=1)\n",
    "\n",
    "    d_yy = np.mean( ( V.T @ (yt - yt_mean) ) ** 2 , axis=1)\n",
    "    \n",
    "    h = d_xy / d_yy\n",
    "    \n",
    "    return h, xt_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1c730c8e33707b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Part 3: GNN and Deep Learning based Estimation\n",
    "\n",
    "### Define Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2196692421d14ac6",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T15:40:31.004301200Z",
     "start_time": "2024-04-24T15:40:31.002296700Z"
    }
   },
   "outputs": [],
   "source": [
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, num_features, K = 10 ):  # K is the order of the Chebyshev polynomial\n",
    "        super(GNN, self).__init__()\n",
    "        \n",
    "        self.conv1 = tg.nn.ChebConv(num_features, 118, K=K, normalization=None)\n",
    "        # self.relu1 = nn.ReLU()\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight):\n",
    "        print(f\"x: {x.shape}, edge_index: {edge_index.shape}, edge_weight: {edge_weight.shape}\")\n",
    "        x = self.conv1(x, edge_index)\n",
    "        # x = self.relu1(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb09e26efe52704",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "(### Define training function\n",
    "\n",
    "In order to run on GPU via CUDA set device accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b411d15073a81b43",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T15:41:17.368073100Z",
     "start_time": "2024-04-24T15:41:17.366401700Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_model(model, yt_train, xt_train, yt_valid, xt_valid, edge_index, edge_weight, batch_size=117, valid_batch_size = 50, epochs=40, lr=0.001, weight_decay=1e-4, path=None, device='cpu'):\n",
    "    \n",
    "    # train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "    # val_loader = DataLoader(valid_data, batch_size=valid_batch_size, shuffle=False)\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    \n",
    "    train_mse, valid_mse = [], []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        idx = np.random.permutation(len(yt_train))\n",
    "        yt_train = yt_train[idx]\n",
    "        xt_train = xt_train[idx]\n",
    "        \n",
    "        # Training\n",
    "        model.train() \n",
    "        train_loss = 0\n",
    "        iters = 0\n",
    "        for i in range(0, len(yt_train), batch_size):\n",
    "            if i + batch_size > len(yt_train):\n",
    "                break\n",
    "            \n",
    "            yt = yt_train[i: i + batch_size]\n",
    "            yt = torch.tensor(yt, dtype=torch.float32)\n",
    "            \n",
    "            xt = xt_train[i: i + batch_size]\n",
    "            xt = torch.tensor(xt, dtype=torch.float32)\n",
    "            \n",
    "            data = Data(x=yt, edge_index=edge_index, y=xt)\n",
    "            data = data.to(device)\n",
    "            edge_index = edge_index.to(device)\n",
    "            edge_weight = edge_weight.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data.x, edge_index, edge_weight)\n",
    "            loss = criterion(output,data.y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += float(loss.item())\n",
    "            iters += 1\n",
    "        train_mse.append(train_loss / iters)\n",
    "        # \n",
    "        # # Validation\n",
    "        # model.eval()\n",
    "        # valid_loss = 0\n",
    "        # iters = 0\n",
    "        # with torch.no_grad():\n",
    "        #     for i in range(0, len(yt_valid), valid_batch_size):\n",
    "        #         yt = yt_valid[i: i + valid_batch_size]\n",
    "        #         yt = torch.tensor(yt, dtype=torch.float32, device=device)\n",
    "        #     \n",
    "        #         xt = xt_valid[i: i + valid_batch_size]\n",
    "        #         xt = torch.tensor(xt, dtype=torch.float32, device=device)\n",
    "        #         \n",
    "        #         xt_hat = model(yt, edge_index, edge_weight)\n",
    "        #         loss = criterion(xt,xt_hat)\n",
    "        #         valid_loss += float(loss.item())\n",
    "        #         iters += 1\n",
    "        #     valid_mse.append(valid_loss / iters)\n",
    "        # \n",
    "        # if valid_mse[-1] == max(valid_mse) and path is not None:\n",
    "        #     print(\"Current State Saved\")\n",
    "        #     torch.save(model.state_dict(), path)\n",
    "        # \n",
    "        # print(f\"Epoch: {epoch}, Train MSE {train_mse[-1]}, Validation MSE {valid_mse[-1]}\")\n",
    "    \n",
    "    valid_mse = 0\n",
    "    return train_mse, valid_mse\n",
    "        \n",
    "        \n",
    "def plot_learning_curve(train_mse, valid_mse):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(train_mse, label='Training MSE', color='blue')\n",
    "    plt.plot(valid_mse, label='Validation MSE', color='black')\n",
    "    plt.title('Training and Validation Losses')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('MSE')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89560b0932c2d00d",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Part 4: Train\n",
    "### Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "filename = 'grid_data_ieee118cdf.mat'\n",
    "grid_data = sio.loadmat(filename)\n",
    "Y = grid_data['Y']\n",
    "N = Y.shape[0]\n",
    "nt = 10000\n",
    "\n",
    "L, Lambda, V = laplacian_evd(Y)\n",
    "xt_total, yt_total = generate_data(nt, Y, Lambda, V, )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T15:37:52.153507300Z",
     "start_time": "2024-04-24T15:37:50.873848800Z"
    }
   },
   "id": "fb08d4251b314b31",
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train GSP-LMMSE Estimator"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bde551fb1df2af"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "316bdbd9af84669c",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-23T20:22:00.435638600Z",
     "start_time": "2024-04-23T20:22:00.428604500Z"
    }
   },
   "outputs": [],
   "source": [
    "h_gsp, b_gsp = train_gsp_lmmse_estimator(xt_total, yt_total, V)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train GNN Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6cc701315e457daf"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d16ed3b52df55492",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T15:41:21.670216800Z",
     "start_time": "2024-04-24T15:41:21.579783Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: torch.Size([117, 118]), edge_index: torch.Size([2, 358]), edge_weight: torch.Size([358])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "index 117 is out of bounds for dimension 0 with size 117",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[22], line 15\u001B[0m\n\u001B[0;32m     11\u001B[0m yt_valid, xt_valid \u001B[38;5;241m=\u001B[39m yt_total[\u001B[38;5;28mint\u001B[39m(\u001B[38;5;28mlen\u001B[39m(yt_total) \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m0.8\u001B[39m):], xt_total[\u001B[38;5;28mint\u001B[39m(\u001B[38;5;28mlen\u001B[39m(xt_total) \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m0.8\u001B[39m):]\n\u001B[0;32m     13\u001B[0m GNN_model\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m---> 15\u001B[0m train_mse, valid_mse \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mGNN_model\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43myt_total\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mxt_total\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43myt_valid\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mxt_valid\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medge_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medge_weight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpath\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpath\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     16\u001B[0m \u001B[38;5;66;03m# plot_learning_curve(train_mse, valid_mse)\u001B[39;00m\n",
      "Cell \u001B[1;32mIn[21], line 36\u001B[0m, in \u001B[0;36mtrain_model\u001B[1;34m(model, yt_train, xt_train, yt_valid, xt_valid, edge_index, edge_weight, batch_size, valid_batch_size, epochs, lr, weight_decay, path, device)\u001B[0m\n\u001B[0;32m     33\u001B[0m edge_weight \u001B[38;5;241m=\u001B[39m edge_weight\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m     35\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[1;32m---> 36\u001B[0m output \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medge_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medge_weight\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     37\u001B[0m loss \u001B[38;5;241m=\u001B[39m criterion(output,data\u001B[38;5;241m.\u001B[39my)\n\u001B[0;32m     38\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()\n",
      "File \u001B[1;32m~\\PycharmProjects\\gsp_final_project\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\gsp_final_project\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "Cell \u001B[1;32mIn[15], line 10\u001B[0m, in \u001B[0;36mGNN.forward\u001B[1;34m(self, x, edge_index, edge_weight)\u001B[0m\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x, edge_index, edge_weight):\n\u001B[0;32m      9\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mx: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mx\u001B[38;5;241m.\u001B[39mshape\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, edge_index: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00medge_index\u001B[38;5;241m.\u001B[39mshape\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, edge_weight: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00medge_weight\u001B[38;5;241m.\u001B[39mshape\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m---> 10\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconv1\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medge_index\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     11\u001B[0m     \u001B[38;5;66;03m# x = self.relu1(x)\u001B[39;00m\n\u001B[0;32m     12\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m x\n",
      "File \u001B[1;32m~\\PycharmProjects\\gsp_final_project\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\gsp_final_project\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\PycharmProjects\\gsp_final_project\\.venv\\Lib\\site-packages\\torch_geometric\\nn\\conv\\cheb_conv.py:151\u001B[0m, in \u001B[0;36mChebConv.forward\u001B[1;34m(self, x, edge_index, edge_weight, batch, lambda_max)\u001B[0m\n\u001B[0;32m    142\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\n\u001B[0;32m    143\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    144\u001B[0m     x: Tensor,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    148\u001B[0m     lambda_max: OptTensor \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m    149\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m--> 151\u001B[0m     edge_index, norm \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m__norm__\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    152\u001B[0m \u001B[43m        \u001B[49m\u001B[43medge_index\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    153\u001B[0m \u001B[43m        \u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msize\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnode_dim\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    154\u001B[0m \u001B[43m        \u001B[49m\u001B[43medge_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    155\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnormalization\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    156\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlambda_max\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    157\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    158\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbatch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    159\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    161\u001B[0m     Tx_0 \u001B[38;5;241m=\u001B[39m x\n\u001B[0;32m    162\u001B[0m     Tx_1 \u001B[38;5;241m=\u001B[39m x  \u001B[38;5;66;03m# Dummy.\u001B[39;00m\n",
      "File \u001B[1;32m~\\PycharmProjects\\gsp_final_project\\.venv\\Lib\\site-packages\\torch_geometric\\nn\\conv\\cheb_conv.py:119\u001B[0m, in \u001B[0;36mChebConv.__norm__\u001B[1;34m(self, edge_index, num_nodes, edge_weight, normalization, lambda_max, dtype, batch)\u001B[0m\n\u001B[0;32m    109\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__norm__\u001B[39m(\n\u001B[0;32m    110\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    111\u001B[0m     edge_index: Tensor,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    117\u001B[0m     batch: OptTensor \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m    118\u001B[0m ):\n\u001B[1;32m--> 119\u001B[0m     edge_index, edge_weight \u001B[38;5;241m=\u001B[39m \u001B[43mget_laplacian\u001B[49m\u001B[43m(\u001B[49m\u001B[43medge_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medge_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    120\u001B[0m \u001B[43m                                            \u001B[49m\u001B[43mnormalization\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    121\u001B[0m \u001B[43m                                            \u001B[49m\u001B[43mnum_nodes\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    122\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m edge_weight \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    124\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m lambda_max \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[1;32m~\\PycharmProjects\\gsp_final_project\\.venv\\Lib\\site-packages\\torch_geometric\\utils\\laplacian.py:69\u001B[0m, in \u001B[0;36mget_laplacian\u001B[1;34m(edge_index, edge_weight, normalization, dtype, num_nodes)\u001B[0m\n\u001B[0;32m     66\u001B[0m num_nodes \u001B[38;5;241m=\u001B[39m maybe_num_nodes(edge_index, num_nodes)\n\u001B[0;32m     68\u001B[0m row, col \u001B[38;5;241m=\u001B[39m edge_index[\u001B[38;5;241m0\u001B[39m], edge_index[\u001B[38;5;241m1\u001B[39m]\n\u001B[1;32m---> 69\u001B[0m deg \u001B[38;5;241m=\u001B[39m \u001B[43mscatter\u001B[49m\u001B[43m(\u001B[49m\u001B[43medge_weight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrow\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdim_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_nodes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreduce\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43msum\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     71\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m normalization \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m     72\u001B[0m     \u001B[38;5;66;03m# L = D - A.\u001B[39;00m\n\u001B[0;32m     73\u001B[0m     edge_index, _ \u001B[38;5;241m=\u001B[39m add_self_loops(edge_index, num_nodes\u001B[38;5;241m=\u001B[39mnum_nodes)\n",
      "File \u001B[1;32m~\\PycharmProjects\\gsp_final_project\\.venv\\Lib\\site-packages\\torch_geometric\\utils\\_scatter.py:75\u001B[0m, in \u001B[0;36mscatter\u001B[1;34m(src, index, dim, dim_size, reduce)\u001B[0m\n\u001B[0;32m     73\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m reduce \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124msum\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m reduce \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124madd\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m     74\u001B[0m     index \u001B[38;5;241m=\u001B[39m broadcast(index, src, dim)\n\u001B[1;32m---> 75\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43msrc\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnew_zeros\u001B[49m\u001B[43m(\u001B[49m\u001B[43msize\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mscatter_add_\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdim\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msrc\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     77\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m reduce \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmean\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m     78\u001B[0m     count \u001B[38;5;241m=\u001B[39m src\u001B[38;5;241m.\u001B[39mnew_zeros(dim_size)\n",
      "\u001B[1;31mRuntimeError\u001B[0m: index 117 is out of bounds for dimension 0 with size 117"
     ]
    }
   ],
   "source": [
    "path = \"./best_GNN_model.pk\"\n",
    "GNN_model = GNN(num_features=N)\n",
    "\n",
    "L_sparse = ssparse.csr_matrix(np.diag(np.diag(L)) -L)\n",
    "edge_index, edge_weight = tg.utils.from_scipy_sparse_matrix(L_sparse)\n",
    "\n",
    "device = 'cpu'\n",
    "\n",
    "# NOTE: yt is the input for the model, and xt is the label, in Data object x is the input and y is the label!\n",
    "yt_train, xt_train = yt_total[:int(len(yt_total) * 0.8)], xt_total[:int(len(xt_total) * 0.8)]\n",
    "yt_valid, xt_valid = yt_total[int(len(yt_total) * 0.8):], xt_total[int(len(xt_total) * 0.8):]\n",
    "\n",
    "GNN_model.to(device)\n",
    "\n",
    "train_mse, valid_mse = train_model(GNN_model, yt_total, xt_total, yt_valid, xt_valid, edge_index, edge_weight, path=path)\n",
    "# plot_learning_curve(train_mse, valid_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1915ae1723bcbb",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Part 4: Comparison"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([118, 1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch_geometric\n",
    "from torch_geometric.nn import ChebConv\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "# Suppose each node initially has 1 feature (could be a simple constant value)\n",
    "num_nodes = 118\n",
    "num_features = 1  # Number of input features\n",
    "out_features = 1  # Number of output features you want after convolution\n",
    "K = 2  # Chebyshev polynomial degree\n",
    "\n",
    "# Create a simple feature matrix with constant features for all nodes\n",
    "x = torch.ones((num_nodes, num_features))\n",
    "\n",
    "# Define your edge indices (example only, replace with your graph's edges)\n",
    "# edge_index must be a 2 x num_edges tensor indicating node connections\n",
    "edge_index = torch.tensor([[0, 1, 1, 2], [1, 0, 2, 1]], dtype=torch.long)\n",
    "\n",
    "# Optionally, you can specify edge weights if your graph is weighted\n",
    "# edge_weight = torch.tensor([...], dtype=torch.float)\n",
    "\n",
    "# Create a PyG graph data object\n",
    "data = Data(x=x, edge_index=edge_index)\n",
    "\n",
    "# Initialize the Chebyshev convolution layer\n",
    "conv = ChebConv(in_channels=num_features, out_channels=out_features, K=K)\n",
    "\n",
    "# Apply the convolution\n",
    "x = conv(x, edge_index)  # if you have edge weights, add: , edge_weight=edge_weight\n",
    "\n",
    "# x now contains the new features of your nodes after the convolution\n",
    "print(x.shape)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T15:42:42.377863200Z",
     "start_time": "2024-04-24T15:42:42.370710500Z"
    }
   },
   "id": "9c031f354a2a3a50",
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146.92237854003906\n",
      "Epoch: 1, Train Loss: 305.4447021484375, Test Loss: 226.54116821289062\n",
      "[0.01 0.12 0.23 0.34 0.45 0.56 0.67 0.78 0.89 1.  ]\n",
      "Epoch: 1, Train Loss: 302.4858703613281, Test Loss: 220.28587341308594\n",
      "Epoch: 11, Train Loss: 25.08798599243164, Test Loss: 29.456289291381836\n",
      "Epoch: 21, Train Loss: 13.775940895080566, Test Loss: 18.41518211364746\n",
      "Epoch: 31, Train Loss: 4.719074249267578, Test Loss: 10.501501083374023\n",
      "Epoch: 41, Train Loss: 2.1199913024902344, Test Loss: 8.29074764251709\n",
      "Epoch: 51, Train Loss: 0.962665855884552, Test Loss: 7.325508117675781\n",
      "Epoch: 61, Train Loss: 0.5312516689300537, Test Loss: 7.0464982986450195\n",
      "Epoch: 71, Train Loss: 0.3373253643512726, Test Loss: 6.977317810058594\n",
      "Epoch: 81, Train Loss: 0.24654310941696167, Test Loss: 6.992523670196533\n",
      "Epoch: 91, Train Loss: 0.198048397898674, Test Loss: 7.031910419464111\n",
      "Epoch: 101, Train Loss: 0.16871300339698792, Test Loss: 7.077186584472656\n",
      "Epoch: 111, Train Loss: 0.1493619978427887, Test Loss: 7.123420715332031\n",
      "Epoch: 121, Train Loss: 0.13568301498889923, Test Loss: 7.165059566497803\n",
      "Epoch: 131, Train Loss: 0.1256176084280014, Test Loss: 7.2063751220703125\n",
      "Epoch: 141, Train Loss: 0.11801966279745102, Test Loss: 7.242571830749512\n",
      "Epoch: 1, Train Loss: 308.0296325683594, Test Loss: 226.41329956054688\n",
      "Epoch: 11, Train Loss: 25.44513511657715, Test Loss: 29.612293243408203\n",
      "Epoch: 21, Train Loss: 14.185120582580566, Test Loss: 18.485855102539062\n",
      "Epoch: 31, Train Loss: 4.780535697937012, Test Loss: 10.32004451751709\n",
      "Epoch: 41, Train Loss: 2.10813045501709, Test Loss: 7.828924179077148\n",
      "Epoch: 51, Train Loss: 0.9914962649345398, Test Loss: 6.777346134185791\n",
      "Epoch: 61, Train Loss: 0.5295389890670776, Test Loss: 6.379911422729492\n",
      "Epoch: 71, Train Loss: 0.3347591757774353, Test Loss: 6.244197368621826\n",
      "Epoch: 81, Train Loss: 0.24289244413375854, Test Loss: 6.21245813369751\n",
      "Epoch: 91, Train Loss: 0.19541887938976288, Test Loss: 6.21053409576416\n",
      "Epoch: 101, Train Loss: 0.1678946167230606, Test Loss: 6.2255859375\n",
      "Epoch: 111, Train Loss: 0.15004384517669678, Test Loss: 6.240800380706787\n",
      "Epoch: 121, Train Loss: 0.13760539889335632, Test Loss: 6.260973930358887\n",
      "Epoch: 131, Train Loss: 0.12854991853237152, Test Loss: 6.280542373657227\n",
      "Epoch: 141, Train Loss: 0.12173529714345932, Test Loss: 6.2981367111206055\n",
      "Epoch: 1, Train Loss: 304.5693054199219, Test Loss: 223.2635498046875\n",
      "Epoch: 11, Train Loss: 24.97136116027832, Test Loss: 29.029972076416016\n",
      "Epoch: 21, Train Loss: 13.908719062805176, Test Loss: 18.282733917236328\n",
      "Epoch: 31, Train Loss: 4.733880996704102, Test Loss: 10.252728462219238\n",
      "Epoch: 41, Train Loss: 2.0811479091644287, Test Loss: 7.871625900268555\n",
      "Epoch: 51, Train Loss: 0.9702067375183105, Test Loss: 6.929995536804199\n",
      "Epoch: 61, Train Loss: 0.526099681854248, Test Loss: 6.594752311706543\n",
      "Epoch: 71, Train Loss: 0.33819225430488586, Test Loss: 6.509303092956543\n",
      "Epoch: 81, Train Loss: 0.24802473187446594, Test Loss: 6.5164690017700195\n",
      "Epoch: 91, Train Loss: 0.19964134693145752, Test Loss: 6.541938304901123\n",
      "Epoch: 101, Train Loss: 0.1717447191476822, Test Loss: 6.584285259246826\n",
      "Epoch: 111, Train Loss: 0.1537352353334427, Test Loss: 6.623310089111328\n",
      "Epoch: 121, Train Loss: 0.14132830500602722, Test Loss: 6.663842678070068\n",
      "Epoch: 131, Train Loss: 0.13239306211471558, Test Loss: 6.70065450668335\n",
      "Epoch: 141, Train Loss: 0.12576797604560852, Test Loss: 6.733803749084473\n",
      "Epoch: 1, Train Loss: 287.5863037109375, Test Loss: 211.97415161132812\n",
      "Epoch: 11, Train Loss: 24.56317901611328, Test Loss: 28.794206619262695\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "from torch_geometric.utils import from_scipy_sparse_matrix\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "# Convert the NumPy array to a scipy sparse matrix (for example, using CSR format)\n",
    "Y_sparse = sp.csr_matrix(grid_init.Y)\n",
    "\n",
    "# Now, use from_scipy_sparse_matrix to convert Y_sparse to edge_index\n",
    "edge_index, _ = from_scipy_sparse_matrix(Y_sparse)\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv, ChebConv\n",
    "import torch.nn.functional as F\n",
    "\n",
    "x = torch.tensor(x_p_test, dtype=torch.float)\n",
    "y = torch.tensor(y_p_test, dtype=torch.float)\n",
    "\n",
    "# Instantiate the MSELoss object\n",
    "mse_loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "# Calculate the MSE loss between x and y\n",
    "loss = mse_loss_fn(x, y)\n",
    "\n",
    "# Print the loss\n",
    "print(loss.item())\n",
    "num_nodes = x.size(0)\n",
    "\n",
    "\n",
    "# Randomly select 80% of the indices for training, the rest for testing\n",
    "indices = np.random.permutation(num_nodes)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create a single Data object\n",
    "data = Data(x=x, edge_index=edge_index, y=y,)\n",
    "\n",
    "edge_index, edge_weight = from_scipy_sparse_matrix(Y_sparse)\n",
    "\n",
    "from torch_geometric.nn import ChebConv\n",
    "\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, num_features, num_classes=118, K=3):  # K is the order of the Chebyshev polynomial\n",
    "        super(GNN, self).__init__()\n",
    "        self.conv1 = ChebConv(num_features, 118, K=K)\n",
    "        # You can add more layers if needed\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight=None):\n",
    "        # If your graph is weighted, pass edge_weight to ChebConv\n",
    "        x = self.conv1(x, edge_index, edge_weight)\n",
    "        # Apply further processing if necessary\n",
    "        return x\n",
    "\n",
    "model = GNN(num_features=x.size(1))  # Adjust num_features based on your x tensor\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.y[:8000], data.edge_index)\n",
    "    squared_diff = (out- data.x[:8000])** 2\n",
    "\n",
    "\n",
    "    # Step 2: Average over nodes\n",
    "    mean_squared_diff_per_example = torch.mean(squared_diff, dim=1)\n",
    "\n",
    "    # Step 3: Average over the dataset\n",
    "    loss = torch.mean(mean_squared_diff_per_example)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "def test():\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        out = model(data.y[8000:], data.edge_index)\n",
    "        squared_diff = (out- data.x[8000:]) ** 2\n",
    "\n",
    "        # Step 2: Average over nodes\n",
    "        mean_squared_diff_per_example = torch.mean(squared_diff, dim=1)\n",
    "\n",
    "        # Step 3: Average over the dataset\n",
    "        loss = torch.mean(mean_squared_diff_per_example)\n",
    "    return loss.item()\n",
    "\n",
    "for epoch in range(100):\n",
    "    train_loss = train()\n",
    "    test_loss = test()\n",
    "    if epoch % 100==0:\n",
    "        print(f'Epoch: {epoch+1}, Train Loss: {train_loss}, Test Loss: {test_loss}')\n",
    "\n",
    "c_ww_values = np.linspace(0.01, 1, 10)\n",
    "print(c_ww_values)\n",
    "\n",
    "train_mse = []\n",
    "test_mse = []\n",
    "start_time_ml = time.time()\n",
    "\n",
    "for i in range(10):\n",
    "    # Generate data for the current c_ww\n",
    "    x, y = util.generate_data_grid(P, grid_init, c_ww=c_ww_values[i])\n",
    "    x = torch.tensor(x, dtype=torch.float)\n",
    "    y = torch.tensor(y, dtype=torch.float)\n",
    "    data = Data(x=x, edge_index=edge_index, y=y)\n",
    "\n",
    "    # Initialize the model\n",
    "    model = GNN(num_features=x.size(1))\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    criterion = torch.nn.MSELoss()\n",
    "\n",
    "\n",
    "    # Your training and testing functions remain the same\n",
    "\n",
    "\n",
    "    # Train and test the model\n",
    "    for epoch in range(150):\n",
    "        train_loss = train()\n",
    "\n",
    "        test_loss = test()\n",
    "        if epoch % 10 == 0:\n",
    "            print(f'Epoch: {epoch + 1}, Train Loss: {train_loss}, Test Loss: {test_loss}')\n",
    "    # Store the final MSE\n",
    "    train_mse.append(train_loss)\n",
    "    test_mse.append(test_loss)\n",
    "\n",
    "end_time_ml = time.time()\n",
    "\n",
    "duration_ml = end_time_ml - start_time_ml\n",
    "print(f\"ML Model Training and Testing Time: {duration_ml} seconds\")\n",
    "\n",
    "# Plotting the MSE vs. c_ww values\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(1/c_ww_values, train_mse, label='Train MSE', marker='o', linestyle='-', color='b')\n",
    "plt.plot(1/c_ww_values, test_mse, label='Test MSE', marker='o', linestyle='-', color='r')\n",
    "plt.xscale('log')  # Set x-axis to log scale\n",
    "plt.xlabel('1/c_ww (Inverse of Noise Variance)')\n",
    "plt.ylabel('MSE')\n",
    "plt.title('MSE vs. 1/c_ww on Log Scale')\n",
    "plt.legend()\n",
    "plt.grid(True, which=\"both\", ls=\"--\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-04-24T15:17:05.967903100Z"
    }
   },
   "id": "747824c15b9b466b",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
