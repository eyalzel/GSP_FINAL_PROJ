{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7269907016b4ac8",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# GSP Final Project\n",
    "In this notebook, we will demonstrate estimation of graph signals using a GSP-based technique vs.  a deep-learning-based technique. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51bc23eb3352395a",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T18:22:29.540084800Z",
     "start_time": "2024-04-21T18:22:27.547360600Z"
    }
   },
   "outputs": [],
   "source": [
    "import util\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import scipy.io as sio\n",
    "import torch_geometric as tg\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Enable CUDA\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Not connected to a GPU')\n",
    "else:\n",
    "  print(gpu_info)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cf0bb1d0827071d9"
  },
  {
   "cell_type": "markdown",
   "id": "ca9c2d7b0168bd9c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Task\n",
    "\n",
    "$$\\mathbf{x} \\longrightarrow  \\boxed{\\text{Physical Model}} \\longrightarrow \\mathbf{y}  \\longrightarrow \\boxed{\\text{Estimator}}  \\longrightarrow \\hat{\\mathbf{x}}$$ \n",
    "\n",
    "### Physical Model\n",
    "$$ \\mathbf{y} = \\mathbf{g}(\\mathbf{x};\\mathbf{L}) + \\mathbf{w} $$\n",
    "\n",
    "- $\\mathbf{x} \\sim p(\\mathbf{x})$.\n",
    "- $\\mathbf{g}$ - a non-linear measurement function.\n",
    "- $\\mathbf{L}$ - the Laplacian matrix of the graph.\n",
    " \n",
    "### Estimator\n",
    "- $\\mathbf{y}$ - input of the estimator\n",
    "- $\\mathbf{x}$ - ground-truth corresponding label\n",
    "- The estimator is given a dataset pairs of $\\{\\mathbf{x_t}, \\mathbf{y_t} \\}_t$ for training.\n",
    "\n",
    "**Goal**: The estimator should recover $\\mathbf{x}$ out of $\\mathbf{y}$ with minimum MSE.\n",
    "#### GSP-based\n",
    "\n",
    "Use a GSP-based technique for estimation.\n",
    "\n",
    "#### GNN-based\n",
    "\n",
    "Use a GNN deep-learning architecture for estimation.\n",
    "\n",
    "**NOTE:**  $\\mathbf{y}$ is the input to the DP model and $\\mathbf{x}$ is the output (i.e., the label) not vise versa!"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Part 1: Physical Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6e5f862e6b2a95fa"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "860a8f216a91cbae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T09:45:49.346354400Z",
     "start_time": "2024-04-21T09:45:49.344133Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def laplacian_evd(Y):\n",
    "    L = - np.imag(Y)\n",
    "    Lambda, V = np.linalg.eig(Y)\n",
    "    sorted_indices = np.argsort(Lambda)\n",
    "    Lambda = Lambda[sorted_indices]\n",
    "    Lambda = np.diag(Lambda)\n",
    "    V = V[:, sorted_indices]\n",
    "    return L, Lambda, V\n",
    "    \n",
    "def g_xL(Y, x):\n",
    "    v = np.exp(1j * x)\n",
    "    g_x = np.real(v * np.conj(Y @ v))\n",
    "    return g_x\n",
    "    \n",
    "def generate_data(nt, Y, Lambda, V, beta=3, c_ww=0.05):\n",
    "    N = Y.shape[0]\n",
    "    xt = (V[:, 1:] @ np.random.multivariate_normal(np.zeros(N - 1), beta * np.diag(1 / np.diag(Lambda)[1:]), nt).T).T\n",
    "    if nt == 1:\n",
    "        xt = xt[0, :]\n",
    "    \n",
    "    yt = np.zeros(xt.shape)\n",
    "    for t in range(0, nt):\n",
    "        yt[t] = g_xL(Y, xt[t])\n",
    "    yt += np.sqrt(c_ww) * np.random.randn(yt.shape)\n",
    "    \n",
    "    return xt, yt\n",
    "\n",
    "filename = 'grid_data_ieee118cdf.mat'\n",
    "data = sio.loadmat(filename)\n",
    "Y = data['Y']\n",
    "N = Y.shape[0]\n",
    "nt = 1000\n",
    "\n",
    "L, Lambda, V = laplacian_evd(Y)\n",
    "xt_train, yt_train = generate_data(nt, Y, Lambda, V, )"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Part 2: GSP-LMMSE Estimator\n",
    "\n",
    "The GSP-LMMSE estimator is defined as an estimator which minimize the MSE among all estimators in the form of a graph filter:\n",
    "$$\n",
    "\\{\\bf{h}, \\bf{b} \\} = \\text{argmin}~ \\mathbb{E} [(\\bf{x} - \\hat{\\bf{x}}(\\bf{y}))^2]\n",
    "$$\n",
    "\n",
    "where $\\hat{\\bf{x}}(\\bf{y}) =  \\bf{V} \\text{diag} (\\bf{h}) \\bf{V}^T \\bf{y}+ \\bf{b}$.\n",
    "\n",
    "A closed form expression would be:\n",
    "$$ \\hat{\\bf{x}}(\\bf{y}) =  \\bf{V} \\text{diag} (\\bf{d}_{\\bf{xy}}\\oslash \\bf{d}_{\\bf{yy}}) \\bf{V}^T \\bf{y} + \\bar{\\bf{x}}$$\n",
    "\n",
    "where $\\bf{d}_{\\bf{xy}} := \\text{diag}(\\text{cov}(\\bf{V}^T \\bf{x}, \\bf{V}^T \\bf{y}))$, $\\bf{d}_{\\bf{yy}} := \\text{diag}(\\text{var}(\\bf{V}^T \\bf{y}))$ and $\\bar{\\bf{x}} :=\\mathbb{E}\\bf{x}$"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2f1667db35646052"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def train_gsp_lmmse_estimator(xt, yt, V):\n",
    "    xt = xt.T     # column vectors representation\n",
    "    yt = yt.T     # column vectors representation\n",
    "\n",
    "    xt_mean = np.mean(xt, axis=1)[:, np.newaxis]\n",
    "    yt_mean = np.mean(yt, axis=1)[:, np.newaxis]\n",
    "\n",
    "    d_xy = np.mean( ( V.T @ (xt - xt_mean) ) * ( V.T @ (yt - yt_mean) ) , axis=1)\n",
    "\n",
    "    d_yy = np.mean( ( V.T @ (yt - yt_mean) ) ** 2 , axis=1)\n",
    "    \n",
    "    h = d_xy / d_yy\n",
    "    \n",
    "    return h, xt_mean"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b344e0714d5c5312"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Part 3: GNN and Deep Learning based Estimation\n",
    "\n",
    "### Define Model Architecture"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2d1c730c8e33707b"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2196692421d14ac6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T09:53:53.611644300Z",
     "start_time": "2024-04-21T09:53:53.604375700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, num_features, K = 10):  # K is the order of the Chebyshev polynomial\n",
    "        super(GNN, self).__init__()\n",
    "        self.conv1 = tg.nn.ChebConv(num_features, 118, K=K, normalization=None)\n",
    "        self.relu1 = nn.ReLU()\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight=None):\n",
    "        x = self.conv1(x, edge_index, edge_weight)\n",
    "        x = self.relu1(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Define GNN training function\n",
    "\n",
    "In order to run on GPU via CUDA set device accordingly."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4cb09e26efe52704"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b411d15073a81b43",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_model(model, train_data, valid_data, batch_size=20, valid_batch_size = 50, epochs=40, lr=0.001, weight_decay=1e-4, path=None, device='cpu'):\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    \n",
    "    train_mse, valid_mse = [], []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        idx = np.random.permutation(len(train_data))\n",
    "        train_data = train_data[idx]\n",
    "        \n",
    "        # Training\n",
    "        train_loss = 0\n",
    "        iters = 0\n",
    "        for i in range(0, len(train_data), batch_size):\n",
    "            model.eval()\n",
    "            \n",
    "            yt = train_data.y[i: i + batch_size]\n",
    "            yt = torch.tensor(yt, dtype=torch.float32, device=device)\n",
    "            \n",
    "            xt = train_data.x[i: i + batch_size]\n",
    "            xt = torch.tensor(xt, dtype=torch.float32, device=device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            xt_hat = model(yt)\n",
    "            loss = criterion(xt,xt_hat)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            iters += 1\n",
    "        train_mse.append(train_loss / iters)\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        valid_loss = 0\n",
    "        iters = 0\n",
    "        with torch.no_grad():\n",
    "            for i in range(0, len(valid_data), valid_batch_size):\n",
    "                yt = train_data.y[i: i + batch_size]\n",
    "                yt = torch.tensor(yt, dtype=torch.float32, device=device)\n",
    "            \n",
    "                xt = train_data.x[i: i + batch_size]\n",
    "                xt = torch.tensor(xt, dtype=torch.float32, device=device)\n",
    "                \n",
    "                xt_hat = model(yt)\n",
    "                loss = criterion(xt,xt_hat)\n",
    "                valid_mse += loss.item()\n",
    "                iters += 1\n",
    "            valid_mse.append(valid_mse / iters)\n",
    "        \n",
    "        if valid_mse[-1] == max(valid_mse) and path is not None:\n",
    "            print(\"Current State Saved\")\n",
    "            torch.save(model.state_dict(), path)\n",
    "        \n",
    "        print(f\"Epoch: {epoch}, Train MSE {train_mse[-1]}, Validation MSE {valid_mse[-1]}\")\n",
    "        \n",
    "def plot_learning_curve(train_mse, valid_mse):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(train_mse, label='Training MSE', color='blue')\n",
    "    plt.plot(valid_mse, label='Validation MSE', color='black')\n",
    "    plt.title('Training and Validation Losses')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('MSE')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfac3cb3558b2f30",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Comparison"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "89560b0932c2d00d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "316bdbd9af84669c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
