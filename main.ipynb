{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7269907016b4ac8",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# GSP Final Project\n",
    "In this notebook, we will demonstrate estimation of graph signals using a GSP-based technique vs.  a deep-learning-based technique. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51bc23eb3352395a",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T14:59:20.255192100Z",
     "start_time": "2024-04-24T14:59:17.274446400Z"
    }
   },
   "outputs": [],
   "source": [
    "import util\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import scipy.sparse as ssparse\n",
    "import scipy.io as sio\n",
    "import torch_geometric as tg\n",
    "import matplotlib.pyplot as plt\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf0bb1d0827071d9",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-22T14:41:56.954085500Z",
     "start_time": "2024-04-22T14:41:56.744596700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Apr 22 17:41:56 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 552.22                 Driver Version: 552.22         CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                     TCC/WDDM  | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4060 ...  WDDM  |   00000000:01:00.0  On |                  N/A |\n",
      "| N/A   38C    P8              3W /   55W |     715MiB /   8188MiB |      3%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A     10320    C+G   C:\\Windows\\explorer.exe                     N/A      |\n",
      "|    0   N/A  N/A     11972    C+G   ...nt.CBS_cw5n1h2txyewy\\SearchHost.exe      N/A      |\n",
      "|    0   N/A  N/A     12092    C+G   ...2txyewy\\StartMenuExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A     12600    C+G   ...utube-music\\3.2.2\\YouTube Music.exe      N/A      |\n",
      "|    0   N/A  N/A     16784    C+G   ...ys\\WinUI3Apps\\PowerToys.Peek.UI.exe      N/A      |\n",
      "|    0   N/A  N/A     16812    C+G   ...crosoft\\Edge\\Application\\msedge.exe      N/A      |\n",
      "|    0   N/A  N/A     17564    C+G   ...werToys\\PowerToys.PowerLauncher.exe      N/A      |\n",
      "|    0   N/A  N/A     17708    C+G   ...ekyb3d8bbwe\\PhoneExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A     18124    C+G   ...GeForce Experience\\NVIDIA Share.exe      N/A      |\n",
      "|    0   N/A  N/A     18172    C+G   ...t.LockApp_cw5n1h2txyewy\\LockApp.exe      N/A      |\n",
      "|    0   N/A  N/A     18604    C+G   ...on\\123.0.2420.97\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A     18768    C+G   ...CBS_cw5n1h2txyewy\\TextInputHost.exe      N/A      |\n",
      "|    0   N/A  N/A     20524    C+G   ...les\\Microsoft OneDrive\\OneDrive.exe      N/A      |\n",
      "|    0   N/A  N/A     20808    C+G   ...Programs\\Microsoft VS Code\\Code.exe      N/A      |\n",
      "|    0   N/A  N/A     21472    C+G   ...ASUSACCI\\ArmouryCrateKeyControl.exe      N/A      |\n",
      "|    0   N/A  N/A     21860    C+G   ...Google\\NearbyShare\\nearby_share.exe      N/A      |\n",
      "|    0   N/A  N/A     21872    C+G   ...8.0_x64__cv1g1gvanyjgm\\WhatsApp.exe      N/A      |\n",
      "|    0   N/A  N/A     29680    C+G   ...5n1h2txyewy\\ShellExperienceHost.exe      N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# Enable CUDA\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Not connected to a GPU')\n",
    "else:\n",
    "  print(gpu_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9c2d7b0168bd9c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Task\n",
    "\n",
    "$$\\mathbf{x} \\longrightarrow  \\boxed{\\text{Physical Model}} \\longrightarrow \\mathbf{y}  \\longrightarrow \\boxed{\\text{Estimator}}  \\longrightarrow \\hat{\\mathbf{x}}$$ \n",
    "\n",
    "### Physical Model\n",
    "$$ \\mathbf{y} = \\mathbf{g}(\\mathbf{x};\\mathbf{L}) + \\mathbf{w} $$\n",
    "\n",
    "- $\\mathbf{x} \\sim p(\\mathbf{x})$.\n",
    "- $\\mathbf{g}$ - a non-linear measurement function.\n",
    "- $\\mathbf{L}$ - the Laplacian matrix of the graph.\n",
    " \n",
    "### Estimator\n",
    "- $\\mathbf{y}$ - input of the estimator\n",
    "- $\\mathbf{x}$ - ground-truth corresponding label\n",
    "- The estimator is given a dataset pairs of $\\{\\mathbf{x_t}, \\mathbf{y_t} \\}_t$ for training.\n",
    "\n",
    "**Goal**: The estimator should recover $\\mathbf{x}$ out of $\\mathbf{y}$ with minimum MSE.\n",
    "#### GSP-based\n",
    "\n",
    "Use a GSP-based technique for estimation.\n",
    "\n",
    "#### GNN-based\n",
    "\n",
    "Use a GNN deep-learning architecture for estimation.\n",
    "\n",
    "**NOTE:**  $\\mathbf{y}$ is the input to the DP model and $\\mathbf{x}$ is the output (i.e., the label) not vise versa!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5f862e6b2a95fa",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Part 1: Physical Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "860a8f216a91cbae",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T14:59:24.028437700Z",
     "start_time": "2024-04-24T14:59:24.025399700Z"
    }
   },
   "outputs": [],
   "source": [
    "def laplacian_evd(Y):\n",
    "    L = - np.imag(Y)\n",
    "    Lambda, V = np.linalg.eig(L)\n",
    "    Lambda = np.real(Lambda)\n",
    "    sorted_indices = np.argsort(Lambda)\n",
    "    Lambda = Lambda[sorted_indices]\n",
    "    Lambda = np.diag(Lambda)\n",
    "    V = V[:, sorted_indices]\n",
    "    return L, Lambda, V\n",
    "    \n",
    "def g_xL(Y, x):\n",
    "    v = np.exp(1j * x)\n",
    "    g_x = np.real(v * np.conj(Y @ v))\n",
    "    return g_x\n",
    "    \n",
    "def generate_data(nt, Y, Lambda, V, beta=3, c_ww=0.05):\n",
    "    N = Y.shape[0]\n",
    "    xt = (V[:, 1:] @ np.random.multivariate_normal(np.zeros(N - 1), beta * np.diag(1 / np.diag(Lambda)[1:]), nt).T).T\n",
    "    if nt == 1:\n",
    "        xt = xt[0, :]\n",
    "    \n",
    "    yt = np.zeros(xt.shape)\n",
    "    for t in range(0, nt):\n",
    "        yt[t] = g_xL(Y, xt[t])\n",
    "    yt += np.sqrt(c_ww) * np.random.randn(yt.shape[0], yt.shape[1])\n",
    "    \n",
    "    return xt, yt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1667db35646052",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Part 2: GSP-LMMSE Estimator\n",
    "\n",
    "The GSP-LMMSE estimator is defined as an estimator which minimize the MSE among all estimators in the form of a graph filter:\n",
    "$$\n",
    "\\{\\bf{h}, \\bf{b} \\} = \\text{argmin}~ \\mathbb{E} [(\\bf{x} - \\hat{\\bf{x}}(\\bf{y}))^2]\n",
    "$$\n",
    "\n",
    "where $\\hat{\\bf{x}}(\\bf{y}) =  \\bf{V} \\text{diag} (\\bf{h}) \\bf{V}^T \\bf{y}+ \\bf{b}$.\n",
    "\n",
    "A closed form expression would be:\n",
    "$$ \\hat{\\bf{x}}(\\bf{y}) =  \\bf{V} \\text{diag} (\\bf{d}_{\\bf{xy}}\\oslash \\bf{d}_{\\bf{yy}}) \\bf{V}^T \\bf{y} + \\bar{\\bf{x}}$$\n",
    "\n",
    "where $\\bf{d}_{\\bf{xy}} := \\text{diag}(\\text{cov}(\\bf{V}^T \\bf{x}, \\bf{V}^T \\bf{y}))$, $\\bf{d}_{\\bf{yy}} := \\text{diag}(\\text{var}(\\bf{V}^T \\bf{y}))$ and $\\bar{\\bf{x}} :=\\mathbb{E}\\bf{x}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b344e0714d5c5312",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T14:59:27.057596800Z",
     "start_time": "2024-04-24T14:59:27.053091200Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_gsp_lmmse_estimator(xt, yt, V):\n",
    "    xt = xt.T     # column vectors representation\n",
    "    yt = yt.T     # column vectors representation\n",
    "\n",
    "    xt_mean = np.mean(xt, axis=1)[:, np.newaxis]\n",
    "    yt_mean = np.mean(yt, axis=1)[:, np.newaxis]\n",
    "\n",
    "    d_xy = np.mean( ( V.T @ (xt - xt_mean) ) * ( V.T @ (yt - yt_mean) ) , axis=1)\n",
    "\n",
    "    d_yy = np.mean( ( V.T @ (yt - yt_mean) ) ** 2 , axis=1)\n",
    "    \n",
    "    h = d_xy / d_yy\n",
    "    \n",
    "    return h, xt_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1c730c8e33707b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Part 3: GNN and Deep Learning based Estimation\n",
    "\n",
    "### Define Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2196692421d14ac6",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T15:31:44.252448300Z",
     "start_time": "2024-04-24T15:31:44.244489100Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch_geometric.nn import ChebConv\n",
    "\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, num_features, num_classes=118, K=3):  # K is the order of the Chebyshev polynomial\n",
    "        super(GNN, self).__init__()\n",
    "        self.conv1 = ChebConv(num_features, 118, K=K)\n",
    "        # You can add more layers if needed\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight=None):\n",
    "        # If your graph is weighted, pass edge_weight to ChebConv\n",
    "        x = self.conv1(x, edge_index, edge_weight)\n",
    "        # Apply further processing if necessary\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb09e26efe52704",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "(### Define training function\n",
    "\n",
    "In order to run on GPU via CUDA set device accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b411d15073a81b43",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T15:36:25.262455100Z",
     "start_time": "2024-04-24T15:36:25.191049400Z"
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "index 100 is out of bounds for dimension 0 with size 100",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[65], line 41\u001B[0m\n\u001B[0;32m     38\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m loss\u001B[38;5;241m.\u001B[39mitem()\n\u001B[0;32m     40\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m100\u001B[39m):\n\u001B[1;32m---> 41\u001B[0m     train_loss \u001B[38;5;241m=\u001B[39m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     42\u001B[0m     test_loss \u001B[38;5;241m=\u001B[39m test()\n\u001B[0;32m     43\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m epoch \u001B[38;5;241m%\u001B[39m \u001B[38;5;241m100\u001B[39m\u001B[38;5;241m==\u001B[39m\u001B[38;5;241m0\u001B[39m:\n",
      "Cell \u001B[1;32mIn[65], line 15\u001B[0m, in \u001B[0;36mtrain\u001B[1;34m()\u001B[0m\n\u001B[0;32m     13\u001B[0m model\u001B[38;5;241m.\u001B[39mtrain()\n\u001B[0;32m     14\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[1;32m---> 15\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43my\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[38;5;241;43m100\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43medge_index\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     16\u001B[0m squared_diff \u001B[38;5;241m=\u001B[39m (out\u001B[38;5;241m-\u001B[39m data\u001B[38;5;241m.\u001B[39mx[:\u001B[38;5;241m100\u001B[39m])\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m \u001B[38;5;241m2\u001B[39m\n\u001B[0;32m     19\u001B[0m \u001B[38;5;66;03m# Step 2: Average over nodes\u001B[39;00m\n",
      "File \u001B[1;32m~\\PycharmProjects\\gsp_final_project\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\gsp_final_project\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "Cell \u001B[1;32mIn[56], line 11\u001B[0m, in \u001B[0;36mGNN.forward\u001B[1;34m(self, x, edge_index, edge_weight)\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x, edge_index, edge_weight\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m     10\u001B[0m     \u001B[38;5;66;03m# If your graph is weighted, pass edge_weight to ChebConv\u001B[39;00m\n\u001B[1;32m---> 11\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconv1\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medge_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medge_weight\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     12\u001B[0m     \u001B[38;5;66;03m# Apply further processing if necessary\u001B[39;00m\n\u001B[0;32m     13\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m x\n",
      "File \u001B[1;32m~\\PycharmProjects\\gsp_final_project\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\gsp_final_project\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\PycharmProjects\\gsp_final_project\\.venv\\Lib\\site-packages\\torch_geometric\\nn\\conv\\cheb_conv.py:151\u001B[0m, in \u001B[0;36mChebConv.forward\u001B[1;34m(self, x, edge_index, edge_weight, batch, lambda_max)\u001B[0m\n\u001B[0;32m    142\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\n\u001B[0;32m    143\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    144\u001B[0m     x: Tensor,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    148\u001B[0m     lambda_max: OptTensor \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m    149\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m--> 151\u001B[0m     edge_index, norm \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m__norm__\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    152\u001B[0m \u001B[43m        \u001B[49m\u001B[43medge_index\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    153\u001B[0m \u001B[43m        \u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msize\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnode_dim\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    154\u001B[0m \u001B[43m        \u001B[49m\u001B[43medge_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    155\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnormalization\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    156\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlambda_max\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    157\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    158\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbatch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    159\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    161\u001B[0m     Tx_0 \u001B[38;5;241m=\u001B[39m x\n\u001B[0;32m    162\u001B[0m     Tx_1 \u001B[38;5;241m=\u001B[39m x  \u001B[38;5;66;03m# Dummy.\u001B[39;00m\n",
      "File \u001B[1;32m~\\PycharmProjects\\gsp_final_project\\.venv\\Lib\\site-packages\\torch_geometric\\nn\\conv\\cheb_conv.py:119\u001B[0m, in \u001B[0;36mChebConv.__norm__\u001B[1;34m(self, edge_index, num_nodes, edge_weight, normalization, lambda_max, dtype, batch)\u001B[0m\n\u001B[0;32m    109\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__norm__\u001B[39m(\n\u001B[0;32m    110\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    111\u001B[0m     edge_index: Tensor,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    117\u001B[0m     batch: OptTensor \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m    118\u001B[0m ):\n\u001B[1;32m--> 119\u001B[0m     edge_index, edge_weight \u001B[38;5;241m=\u001B[39m \u001B[43mget_laplacian\u001B[49m\u001B[43m(\u001B[49m\u001B[43medge_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medge_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    120\u001B[0m \u001B[43m                                            \u001B[49m\u001B[43mnormalization\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    121\u001B[0m \u001B[43m                                            \u001B[49m\u001B[43mnum_nodes\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    122\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m edge_weight \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    124\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m lambda_max \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[1;32m~\\PycharmProjects\\gsp_final_project\\.venv\\Lib\\site-packages\\torch_geometric\\utils\\laplacian.py:69\u001B[0m, in \u001B[0;36mget_laplacian\u001B[1;34m(edge_index, edge_weight, normalization, dtype, num_nodes)\u001B[0m\n\u001B[0;32m     66\u001B[0m num_nodes \u001B[38;5;241m=\u001B[39m maybe_num_nodes(edge_index, num_nodes)\n\u001B[0;32m     68\u001B[0m row, col \u001B[38;5;241m=\u001B[39m edge_index[\u001B[38;5;241m0\u001B[39m], edge_index[\u001B[38;5;241m1\u001B[39m]\n\u001B[1;32m---> 69\u001B[0m deg \u001B[38;5;241m=\u001B[39m \u001B[43mscatter\u001B[49m\u001B[43m(\u001B[49m\u001B[43medge_weight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrow\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdim_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_nodes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreduce\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43msum\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     71\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m normalization \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m     72\u001B[0m     \u001B[38;5;66;03m# L = D - A.\u001B[39;00m\n\u001B[0;32m     73\u001B[0m     edge_index, _ \u001B[38;5;241m=\u001B[39m add_self_loops(edge_index, num_nodes\u001B[38;5;241m=\u001B[39mnum_nodes)\n",
      "File \u001B[1;32m~\\PycharmProjects\\gsp_final_project\\.venv\\Lib\\site-packages\\torch_geometric\\utils\\_scatter.py:75\u001B[0m, in \u001B[0;36mscatter\u001B[1;34m(src, index, dim, dim_size, reduce)\u001B[0m\n\u001B[0;32m     73\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m reduce \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124msum\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m reduce \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124madd\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m     74\u001B[0m     index \u001B[38;5;241m=\u001B[39m broadcast(index, src, dim)\n\u001B[1;32m---> 75\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43msrc\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnew_zeros\u001B[49m\u001B[43m(\u001B[49m\u001B[43msize\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mscatter_add_\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdim\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msrc\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     77\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m reduce \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmean\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m     78\u001B[0m     count \u001B[38;5;241m=\u001B[39m src\u001B[38;5;241m.\u001B[39mnew_zeros(dim_size)\n",
      "\u001B[1;31mRuntimeError\u001B[0m: index 100 is out of bounds for dimension 0 with size 100"
     ]
    }
   ],
   "source": [
    "# x_p_test, y_p_test = util.generate_data_grid(P, grid_init, c_ww=1)\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# x = torch.tensor(x_p_test, dtype=torch.float)\n",
    "# y = torch.tensor(y_p_test, dtype=torch.float)\n",
    "\n",
    "# print(x.size(1))\n",
    "model = GNN(num_features=118)  # Adjust num_features based on your x tensor\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.y[:100], data.edge_index)\n",
    "    squared_diff = (out- data.x[:100])** 2\n",
    "\n",
    "\n",
    "    # Step 2: Average over nodes\n",
    "    mean_squared_diff_per_example = torch.mean(squared_diff, dim=1)\n",
    "\n",
    "    # Step 3: Average over the dataset\n",
    "    loss = torch.mean(mean_squared_diff_per_example)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "def test():\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        out = model(data.y[8000:], data.edge_index)\n",
    "        squared_diff = (out- data.x[8000:]) ** 2\n",
    "\n",
    "        # Step 2: Average over nodes\n",
    "        mean_squared_diff_per_example = torch.mean(squared_diff, dim=1)\n",
    "\n",
    "        # Step 3: Average over the dataset\n",
    "        loss = torch.mean(mean_squared_diff_per_example)\n",
    "    return loss.item()\n",
    "\n",
    "for epoch in range(100):\n",
    "    train_loss = train()\n",
    "    test_loss = test()\n",
    "    if epoch % 100==0:\n",
    "        print(f'Epoch: {epoch+1}, Train Loss: {train_loss}, Test Loss: {test_loss}')\n",
    "\n",
    "c_ww_values = np.linspace(0.01, 1, 10)\n",
    "print(c_ww_values)\n",
    "\n",
    "train_mse = []\n",
    "test_mse = []\n",
    "start_time_ml = time.time()\n",
    "\n",
    "for i in range(10):\n",
    "    # Generate data for the current c_ww\n",
    "    x, y = util.generate_data_grid(P, grid_init, c_ww=c_ww_values[i])\n",
    "    x = torch.tensor(x, dtype=torch.float)\n",
    "    y = torch.tensor(y, dtype=torch.float)\n",
    "    data = Data(x=x, edge_index=edge_index, y=y)\n",
    "\n",
    "    # Initialize the model\n",
    "    model = GNN(num_features=x.size(1))\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    criterion = torch.nn.MSELoss()\n",
    "\n",
    "\n",
    "    # Your training and testing functions remain the same\n",
    "\n",
    "\n",
    "    # Train and test the model\n",
    "    for epoch in range(150):\n",
    "        train_loss = train()\n",
    "\n",
    "        test_loss = test()\n",
    "        if epoch % 10 == 0:\n",
    "            print(f'Epoch: {epoch + 1}, Train Loss: {train_loss}, Test Loss: {test_loss}')\n",
    "    # Store the final MSE\n",
    "    train_mse.append(train_loss)\n",
    "    test_mse.append(test_loss)\n",
    "\n",
    "end_time_ml = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89560b0932c2d00d",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Part 4: Train\n",
    "### Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "filename = 'grid_data_ieee118cdf.mat'\n",
    "grid_data = sio.loadmat(filename)\n",
    "Y = grid_data['Y']\n",
    "N = Y.shape[0]\n",
    "nt = 1000\n",
    "\n",
    "L, Lambda, V = laplacian_evd(Y)\n",
    "xt_total, yt_total = generate_data(nt, Y, Lambda, V, )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T14:59:38.292899700Z",
     "start_time": "2024-04-24T14:59:38.142983300Z"
    }
   },
   "id": "fb08d4251b314b31",
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train GSP-LMMSE Estimator"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bde551fb1df2af"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "316bdbd9af84669c",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-23T20:22:00.435638600Z",
     "start_time": "2024-04-23T20:22:00.428604500Z"
    }
   },
   "outputs": [],
   "source": [
    "h_gsp, b_gsp = train_gsp_lmmse_estimator(xt_total, yt_total, V)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train GNN Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6cc701315e457daf"
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d16ed3b52df55492",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T15:31:15.016950600Z",
     "start_time": "2024-04-24T15:31:14.959892800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: (1000, 118), edge_index: torch.Size([2, 358]), edge_weight: torch.Size([358])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'int' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[55], line 15\u001B[0m\n\u001B[0;32m     11\u001B[0m yt_valid, xt_valid \u001B[38;5;241m=\u001B[39m yt_total[\u001B[38;5;28mint\u001B[39m(\u001B[38;5;28mlen\u001B[39m(yt_total) \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m0.8\u001B[39m):], xt_total[\u001B[38;5;28mint\u001B[39m(\u001B[38;5;28mlen\u001B[39m(xt_total) \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m0.8\u001B[39m):]\n\u001B[0;32m     13\u001B[0m GNN_model\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m---> 15\u001B[0m train_mse, valid_mse \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mGNN_model\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43myt_total\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mxt_total\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43myt_valid\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mxt_valid\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medge_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medge_weight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpath\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpath\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     16\u001B[0m \u001B[38;5;66;03m# plot_learning_curve(train_mse, valid_mse)\u001B[39;00m\n",
      "Cell \u001B[1;32mIn[51], line 36\u001B[0m, in \u001B[0;36mtrain_model\u001B[1;34m(model, yt_train, xt_train, yt_valid, xt_valid, edge_index, edge_weight, batch_size, valid_batch_size, epochs, lr, weight_decay, path, device)\u001B[0m\n\u001B[0;32m     33\u001B[0m edge_weight \u001B[38;5;241m=\u001B[39m edge_weight\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m     35\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[1;32m---> 36\u001B[0m output \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43medge_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medge_weight\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     37\u001B[0m loss \u001B[38;5;241m=\u001B[39m criterion(output,data\u001B[38;5;241m.\u001B[39my)\n\u001B[0;32m     38\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()\n",
      "File \u001B[1;32m~\\PycharmProjects\\gsp_final_project\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\gsp_final_project\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "Cell \u001B[1;32mIn[49], line 10\u001B[0m, in \u001B[0;36mGNN.forward\u001B[1;34m(self, x, edge_index, edge_weight)\u001B[0m\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x, edge_index, edge_weight):\n\u001B[0;32m      9\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mx: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mx\u001B[38;5;241m.\u001B[39mshape\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, edge_index: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00medge_index\u001B[38;5;241m.\u001B[39mshape\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, edge_weight: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00medge_weight\u001B[38;5;241m.\u001B[39mshape\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m---> 10\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconv1\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medge_index\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     11\u001B[0m     \u001B[38;5;66;03m# x = self.relu1(x)\u001B[39;00m\n\u001B[0;32m     12\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m x\n",
      "File \u001B[1;32m~\\PycharmProjects\\gsp_final_project\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\gsp_final_project\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\PycharmProjects\\gsp_final_project\\.venv\\Lib\\site-packages\\torch_geometric\\nn\\conv\\cheb_conv.py:153\u001B[0m, in \u001B[0;36mChebConv.forward\u001B[1;34m(self, x, edge_index, edge_weight, batch, lambda_max)\u001B[0m\n\u001B[0;32m    142\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\n\u001B[0;32m    143\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    144\u001B[0m     x: Tensor,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    148\u001B[0m     lambda_max: OptTensor \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m    149\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m    151\u001B[0m     edge_index, norm \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__norm__(\n\u001B[0;32m    152\u001B[0m         edge_index,\n\u001B[1;32m--> 153\u001B[0m         \u001B[43mx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msize\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnode_dim\u001B[49m\u001B[43m)\u001B[49m,\n\u001B[0;32m    154\u001B[0m         edge_weight,\n\u001B[0;32m    155\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnormalization,\n\u001B[0;32m    156\u001B[0m         lambda_max,\n\u001B[0;32m    157\u001B[0m         dtype\u001B[38;5;241m=\u001B[39mx\u001B[38;5;241m.\u001B[39mdtype,\n\u001B[0;32m    158\u001B[0m         batch\u001B[38;5;241m=\u001B[39mbatch,\n\u001B[0;32m    159\u001B[0m     )\n\u001B[0;32m    161\u001B[0m     Tx_0 \u001B[38;5;241m=\u001B[39m x\n\u001B[0;32m    162\u001B[0m     Tx_1 \u001B[38;5;241m=\u001B[39m x  \u001B[38;5;66;03m# Dummy.\u001B[39;00m\n",
      "\u001B[1;31mTypeError\u001B[0m: 'int' object is not callable"
     ]
    }
   ],
   "source": [
    "path = \"./best_GNN_model.pk\"\n",
    "GNN_model = GNN(num_features=118)\n",
    "\n",
    "L_sparse = ssparse.csr_matrix(np.diag(np.diag(L)) - L)\n",
    "edge_index, edge_weight = tg.utils.from_scipy_sparse_matrix(L_sparse)\n",
    "\n",
    "device = 'cpu'\n",
    "\n",
    "# NOTE: yt is the input for the model, and xt is the label, in Data object x is the input and y is the label!\n",
    "yt_train, xt_train = yt_total[:int(len(yt_total) * 0.8)], xt_total[:int(len(xt_total) * 0.8)]\n",
    "yt_valid, xt_valid = yt_total[int(len(yt_total) * 0.8):], xt_total[int(len(xt_total) * 0.8):]\n",
    "\n",
    "GNN_model.to(device)\n",
    "\n",
    "train_mse, valid_mse = train_model(GNN_model, yt_total, xt_total, yt_valid, xt_valid, edge_index, edge_weight, path=path)\n",
    "# plot_learning_curve(train_mse, valid_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1915ae1723bcbb",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Part 4: Comparison"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146.92237854003906\n",
      "118\n",
      "Epoch: 1, Train Loss: 317.8051452636719, Test Loss: 236.82020568847656\n",
      "[0.01 0.12 0.23 0.34 0.45 0.56 0.67 0.78 0.89 1.  ]\n",
      "Epoch: 1, Train Loss: 307.84576416015625, Test Loss: 227.7606201171875\n",
      "Epoch: 11, Train Loss: 26.510807037353516, Test Loss: 30.32475471496582\n",
      "Epoch: 21, Train Loss: 13.755607604980469, Test Loss: 18.194543838500977\n",
      "Epoch: 31, Train Loss: 4.932769298553467, Test Loss: 10.334019660949707\n",
      "Epoch: 41, Train Loss: 2.1377923488616943, Test Loss: 7.824146747589111\n",
      "Epoch: 51, Train Loss: 0.9932155013084412, Test Loss: 6.906777381896973\n",
      "Epoch: 61, Train Loss: 0.5420362949371338, Test Loss: 6.559720039367676\n",
      "Epoch: 71, Train Loss: 0.3418639302253723, Test Loss: 6.477587699890137\n",
      "Epoch: 81, Train Loss: 0.2486754059791565, Test Loss: 6.476356029510498\n",
      "Epoch: 91, Train Loss: 0.19846972823143005, Test Loss: 6.5006327629089355\n",
      "Epoch: 101, Train Loss: 0.16836859285831451, Test Loss: 6.5372819900512695\n",
      "Epoch: 111, Train Loss: 0.1487843096256256, Test Loss: 6.582650661468506\n",
      "Epoch: 121, Train Loss: 0.1351626217365265, Test Loss: 6.626227855682373\n",
      "Epoch: 131, Train Loss: 0.1252080798149109, Test Loss: 6.66730260848999\n",
      "Epoch: 141, Train Loss: 0.11777494847774506, Test Loss: 6.706373691558838\n",
      "Epoch: 1, Train Loss: 309.2930603027344, Test Loss: 227.83132934570312\n",
      "Epoch: 11, Train Loss: 25.22828483581543, Test Loss: 29.742273330688477\n",
      "Epoch: 21, Train Loss: 14.020129203796387, Test Loss: 18.742671966552734\n",
      "Epoch: 31, Train Loss: 4.801386833190918, Test Loss: 10.684830665588379\n",
      "Epoch: 41, Train Loss: 2.1278531551361084, Test Loss: 8.209125518798828\n",
      "Epoch: 51, Train Loss: 0.9726138710975647, Test Loss: 7.204296112060547\n",
      "Epoch: 61, Train Loss: 0.5236707925796509, Test Loss: 6.860655784606934\n",
      "Epoch: 71, Train Loss: 0.332001656293869, Test Loss: 6.7496843338012695\n",
      "Epoch: 81, Train Loss: 0.24059055745601654, Test Loss: 6.711622714996338\n",
      "Epoch: 91, Train Loss: 0.19335730373859406, Test Loss: 6.738731384277344\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[43], line 127\u001B[0m\n\u001B[0;32m    122\u001B[0m \u001B[38;5;66;03m# Your training and testing functions remain the same\u001B[39;00m\n\u001B[0;32m    123\u001B[0m \n\u001B[0;32m    124\u001B[0m \n\u001B[0;32m    125\u001B[0m \u001B[38;5;66;03m# Train and test the model\u001B[39;00m\n\u001B[0;32m    126\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m150\u001B[39m):\n\u001B[1;32m--> 127\u001B[0m     train_loss \u001B[38;5;241m=\u001B[39m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    129\u001B[0m     test_loss \u001B[38;5;241m=\u001B[39m test()\n\u001B[0;32m    130\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m epoch \u001B[38;5;241m%\u001B[39m \u001B[38;5;241m10\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "Cell \u001B[1;32mIn[43], line 71\u001B[0m, in \u001B[0;36mtrain\u001B[1;34m()\u001B[0m\n\u001B[0;32m     69\u001B[0m model\u001B[38;5;241m.\u001B[39mtrain()\n\u001B[0;32m     70\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[1;32m---> 71\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43my\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[38;5;241;43m8000\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43medge_index\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     72\u001B[0m squared_diff \u001B[38;5;241m=\u001B[39m (out\u001B[38;5;241m-\u001B[39m data\u001B[38;5;241m.\u001B[39mx[:\u001B[38;5;241m8000\u001B[39m])\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m \u001B[38;5;241m2\u001B[39m\n\u001B[0;32m     75\u001B[0m \u001B[38;5;66;03m# Step 2: Average over nodes\u001B[39;00m\n",
      "File \u001B[1;32m~\\PycharmProjects\\gsp_final_project\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\gsp_final_project\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "Cell \u001B[1;32mIn[43], line 60\u001B[0m, in \u001B[0;36mGNN.forward\u001B[1;34m(self, x, edge_index, edge_weight)\u001B[0m\n\u001B[0;32m     58\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x, edge_index, edge_weight\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m     59\u001B[0m     \u001B[38;5;66;03m# If your graph is weighted, pass edge_weight to ChebConv\u001B[39;00m\n\u001B[1;32m---> 60\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconv1\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medge_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medge_weight\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     61\u001B[0m     \u001B[38;5;66;03m# Apply further processing if necessary\u001B[39;00m\n\u001B[0;32m     62\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m x\n",
      "File \u001B[1;32m~\\PycharmProjects\\gsp_final_project\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\gsp_final_project\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\PycharmProjects\\gsp_final_project\\.venv\\Lib\\site-packages\\torch_geometric\\nn\\conv\\cheb_conv.py:173\u001B[0m, in \u001B[0;36mChebConv.forward\u001B[1;34m(self, x, edge_index, edge_weight, batch, lambda_max)\u001B[0m\n\u001B[0;32m    171\u001B[0m     Tx_2 \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpropagate(edge_index, x\u001B[38;5;241m=\u001B[39mTx_1, norm\u001B[38;5;241m=\u001B[39mnorm)\n\u001B[0;32m    172\u001B[0m     Tx_2 \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m2.\u001B[39m \u001B[38;5;241m*\u001B[39m Tx_2 \u001B[38;5;241m-\u001B[39m Tx_0\n\u001B[1;32m--> 173\u001B[0m     out \u001B[38;5;241m=\u001B[39m out \u001B[38;5;241m+\u001B[39m \u001B[43mlin\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mTx_2\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    174\u001B[0m     Tx_0, Tx_1 \u001B[38;5;241m=\u001B[39m Tx_1, Tx_2\n\u001B[0;32m    176\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbias \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[1;32m~\\PycharmProjects\\gsp_final_project\\.venv\\Lib\\site-packages\\torch_geometric\\nn\\dense\\linear.py:147\u001B[0m, in \u001B[0;36mLinear.forward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m    141\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m    142\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"Forward pass.\u001B[39;00m\n\u001B[0;32m    143\u001B[0m \n\u001B[0;32m    144\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[0;32m    145\u001B[0m \u001B[38;5;124;03m        x (torch.Tensor): The input features.\u001B[39;00m\n\u001B[0;32m    146\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 147\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinear\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "from torch_geometric.utils import from_scipy_sparse_matrix\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "# Convert the NumPy array to a scipy sparse matrix (for example, using CSR format)\n",
    "Y_sparse = sp.csr_matrix(grid_init.Y)\n",
    "\n",
    "# Now, use from_scipy_sparse_matrix to convert Y_sparse to edge_index\n",
    "edge_index, _ = from_scipy_sparse_matrix(Y_sparse)\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv, ChebConv\n",
    "import torch.nn.functional as F\n",
    "\n",
    "x = torch.tensor(x_p_test, dtype=torch.float)\n",
    "y = torch.tensor(y_p_test, dtype=torch.float)\n",
    "\n",
    "# Instantiate the MSELoss object\n",
    "mse_loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "# Calculate the MSE loss between x and y\n",
    "loss = mse_loss_fn(x, y)\n",
    "\n",
    "# Print the loss\n",
    "print(loss.item())\n",
    "num_nodes = x.size(0)\n",
    "print(x.size(1))\n",
    "\n",
    "# Randomly select 80% of the indices for training, the rest for testing\n",
    "indices = np.random.permutation(num_nodes)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create a single Data object\n",
    "data = Data(x=x, edge_index=edge_index, y=y,)\n",
    "\n",
    "edge_index, edge_weight = from_scipy_sparse_matrix(Y_sparse)\n",
    "\n",
    "from torch_geometric.nn import ChebConv\n",
    "\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, num_features, num_classes=118, K=3):  # K is the order of the Chebyshev polynomial\n",
    "        super(GNN, self).__init__()\n",
    "        self.conv1 = ChebConv(num_features, 118, K=K)\n",
    "        # You can add more layers if needed\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight=None):\n",
    "        # If your graph is weighted, pass edge_weight to ChebConv\n",
    "        x = self.conv1(x, edge_index, edge_weight)\n",
    "        # Apply further processing if necessary\n",
    "        return x\n",
    "\n",
    "model = GNN(num_features=x.size(1))  # Adjust num_features based on your x tensor\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.y[:8000], data.edge_index)\n",
    "    squared_diff = (out- data.x[:8000])** 2\n",
    "\n",
    "\n",
    "    # Step 2: Average over nodes\n",
    "    mean_squared_diff_per_example = torch.mean(squared_diff, dim=1)\n",
    "\n",
    "    # Step 3: Average over the dataset\n",
    "    loss = torch.mean(mean_squared_diff_per_example)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "def test():\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        out = model(data.y[8000:], data.edge_index)\n",
    "        squared_diff = (out- data.x[8000:]) ** 2\n",
    "\n",
    "        # Step 2: Average over nodes\n",
    "        mean_squared_diff_per_example = torch.mean(squared_diff, dim=1)\n",
    "\n",
    "        # Step 3: Average over the dataset\n",
    "        loss = torch.mean(mean_squared_diff_per_example)\n",
    "    return loss.item()\n",
    "\n",
    "for epoch in range(100):\n",
    "    train_loss = train()\n",
    "    test_loss = test()\n",
    "    if epoch % 100==0:\n",
    "        print(f'Epoch: {epoch+1}, Train Loss: {train_loss}, Test Loss: {test_loss}')\n",
    "\n",
    "c_ww_values = np.linspace(0.01, 1, 10)\n",
    "print(c_ww_values)\n",
    "\n",
    "train_mse = []\n",
    "test_mse = []\n",
    "start_time_ml = time.time()\n",
    "\n",
    "for i in range(10):\n",
    "    # Generate data for the current c_ww\n",
    "    x, y = util.generate_data_grid(P, grid_init, c_ww=c_ww_values[i])\n",
    "    x = torch.tensor(x, dtype=torch.float)\n",
    "    y = torch.tensor(y, dtype=torch.float)\n",
    "    data = Data(x=x, edge_index=edge_index, y=y)\n",
    "\n",
    "    # Initialize the model\n",
    "    model = GNN(num_features=x.size(1))\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    criterion = torch.nn.MSELoss()\n",
    "\n",
    "\n",
    "    # Your training and testing functions remain the same\n",
    "\n",
    "\n",
    "    # Train and test the model\n",
    "    for epoch in range(150):\n",
    "        train_loss = train()\n",
    "\n",
    "        test_loss = test()\n",
    "        if epoch % 10 == 0:\n",
    "            print(f'Epoch: {epoch + 1}, Train Loss: {train_loss}, Test Loss: {test_loss}')\n",
    "    # Store the final MSE\n",
    "    train_mse.append(train_loss)\n",
    "    test_mse.append(test_loss)\n",
    "\n",
    "end_time_ml = time.time()\n",
    "\n",
    "duration_ml = end_time_ml - start_time_ml\n",
    "print(f\"ML Model Training and Testing Time: {duration_ml} seconds\")\n",
    "\n",
    "# Plotting the MSE vs. c_ww values\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(1/c_ww_values, train_mse, label='Train MSE', marker='o', linestyle='-', color='b')\n",
    "plt.plot(1/c_ww_values, test_mse, label='Test MSE', marker='o', linestyle='-', color='r')\n",
    "plt.xscale('log')  # Set x-axis to log scale\n",
    "plt.xlabel('1/c_ww (Inverse of Noise Variance)')\n",
    "plt.ylabel('MSE')\n",
    "plt.title('MSE vs. 1/c_ww on Log Scale')\n",
    "plt.legend()\n",
    "plt.grid(True, which=\"both\", ls=\"--\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T15:20:26.444864400Z",
     "start_time": "2024-04-24T15:20:17.913331800Z"
    }
   },
   "id": "747824c15b9b466b",
   "execution_count": 43
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
